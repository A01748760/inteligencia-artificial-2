2022-11-09 16:21:21,785 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,786 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)
  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=36, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-11-09 16:21:21,790 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,791 Corpus: "Corpus: 26 train + 1000 dev + 3850 test sentences"
2022-11-09 16:21:21,791 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,791 Parameters:
2022-11-09 16:21:21,792  - learning_rate: "0.050000"
2022-11-09 16:21:21,792  - mini_batch_size: "32"
2022-11-09 16:21:21,793  - patience: "3"
2022-11-09 16:21:21,793  - anneal_factor: "0.5"
2022-11-09 16:21:21,794  - max_epochs: "15"
2022-11-09 16:21:21,794  - shuffle: "True"
2022-11-09 16:21:21,795  - train_with_dev: "False"
2022-11-09 16:21:21,795  - batch_growth_annealing: "False"
2022-11-09 16:21:21,796 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,796 Model training base path: "resources\taggers\example-ner"
2022-11-09 16:21:21,797 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,797 Device: cpu
2022-11-09 16:21:21,798 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:21,798 Embeddings storage mode: cpu
2022-11-09 16:21:21,799 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:22,432 epoch 1 - iter 1/1 - loss 3.85604030 - samples/sec: 50.66 - lr: 0.050000
2022-11-09 16:21:22,433 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:22,433 EPOCH 1 done: loss 3.8560 - lr 0.050000
2022-11-09 16:21:27,418 Evaluating as a multi-label problem: False
2022-11-09 16:21:27,516 DEV : loss 3.4872236251831055 - f1-score (micro avg)  0.0007
2022-11-09 16:21:27,602 BAD EPOCHS (no improvement): 0
2022-11-09 16:21:27,603 saving best model
2022-11-09 16:21:29,038 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:29,512 epoch 2 - iter 1/1 - loss 3.46125360 - samples/sec: 67.66 - lr: 0.050000
2022-11-09 16:21:29,513 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:29,513 EPOCH 2 done: loss 3.4613 - lr 0.050000
2022-11-09 16:21:34,456 Evaluating as a multi-label problem: False
2022-11-09 16:21:34,544 DEV : loss 3.0720841884613037 - f1-score (micro avg)  0.0007
2022-11-09 16:21:34,629 BAD EPOCHS (no improvement): 0
2022-11-09 16:21:34,629 saving best model
2022-11-09 16:21:35,942 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:36,600 epoch 3 - iter 1/1 - loss 2.95523694 - samples/sec: 48.73 - lr: 0.050000
2022-11-09 16:21:36,602 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:36,602 EPOCH 3 done: loss 2.9552 - lr 0.050000
2022-11-09 16:21:43,266 Evaluating as a multi-label problem: False
2022-11-09 16:21:43,366 DEV : loss 2.62298583984375 - f1-score (micro avg)  0.0002
2022-11-09 16:21:43,463 BAD EPOCHS (no improvement): 1
2022-11-09 16:21:43,464 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:44,050 epoch 4 - iter 1/1 - loss 2.51870657 - samples/sec: 54.75 - lr: 0.050000
2022-11-09 16:21:44,051 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:44,052 EPOCH 4 done: loss 2.5187 - lr 0.050000
2022-11-09 16:21:49,878 Evaluating as a multi-label problem: False
2022-11-09 16:21:49,955 DEV : loss 2.1262366771698 - f1-score (micro avg)  0.0003
2022-11-09 16:21:50,040 BAD EPOCHS (no improvement): 2
2022-11-09 16:21:50,041 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:50,567 epoch 5 - iter 1/1 - loss 2.04120027 - samples/sec: 61.03 - lr: 0.050000
2022-11-09 16:21:50,567 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:50,567 EPOCH 5 done: loss 2.0412 - lr 0.050000
2022-11-09 16:21:55,458 Evaluating as a multi-label problem: False
2022-11-09 16:21:55,499 DEV : loss 1.6062967777252197 - f1-score (micro avg)  0.0008
2022-11-09 16:21:55,582 BAD EPOCHS (no improvement): 0
2022-11-09 16:21:55,583 saving best model
2022-11-09 16:21:57,104 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:57,637 epoch 6 - iter 1/1 - loss 1.49007170 - samples/sec: 60.36 - lr: 0.050000
2022-11-09 16:21:57,637 ----------------------------------------------------------------------------------------------------
2022-11-09 16:21:57,638 EPOCH 6 done: loss 1.4901 - lr 0.050000
2022-11-09 16:22:02,614 Evaluating as a multi-label problem: False
2022-11-09 16:22:02,645 DEV : loss 1.140008807182312 - f1-score (micro avg)  0.0
2022-11-09 16:22:02,736 BAD EPOCHS (no improvement): 1
2022-11-09 16:22:02,737 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:03,291 epoch 7 - iter 1/1 - loss 1.09372019 - samples/sec: 57.83 - lr: 0.050000
2022-11-09 16:22:03,293 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:03,293 EPOCH 7 done: loss 1.0937 - lr 0.050000
2022-11-09 16:22:07,792 Evaluating as a multi-label problem: False
2022-11-09 16:22:07,818 DEV : loss 0.842388927936554 - f1-score (micro avg)  0.0
2022-11-09 16:22:07,901 BAD EPOCHS (no improvement): 2
2022-11-09 16:22:07,902 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:08,503 epoch 8 - iter 1/1 - loss 0.78772872 - samples/sec: 53.35 - lr: 0.050000
2022-11-09 16:22:08,504 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:08,505 EPOCH 8 done: loss 0.7877 - lr 0.050000
2022-11-09 16:22:13,545 Evaluating as a multi-label problem: False
2022-11-09 16:22:13,575 DEV : loss 0.6944868564605713 - f1-score (micro avg)  0.0
2022-11-09 16:22:13,667 BAD EPOCHS (no improvement): 3
2022-11-09 16:22:13,668 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:14,223 epoch 9 - iter 1/1 - loss 0.67307566 - samples/sec: 57.83 - lr: 0.050000
2022-11-09 16:22:14,224 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:14,224 EPOCH 9 done: loss 0.6731 - lr 0.050000
2022-11-09 16:22:19,120 Evaluating as a multi-label problem: False
2022-11-09 16:22:19,142 DEV : loss 0.6389280557632446 - f1-score (micro avg)  0.0
2022-11-09 16:22:19,240 Epoch     9: reducing learning rate of group 0 to 2.5000e-02.
2022-11-09 16:22:19,241 BAD EPOCHS (no improvement): 4
2022-11-09 16:22:19,242 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:19,721 epoch 10 - iter 1/1 - loss 0.58252056 - samples/sec: 66.98 - lr: 0.025000
2022-11-09 16:22:19,721 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:19,722 EPOCH 10 done: loss 0.5825 - lr 0.025000
2022-11-09 16:22:24,494 Evaluating as a multi-label problem: False
2022-11-09 16:22:24,517 DEV : loss 0.6299160718917847 - f1-score (micro avg)  0.0
2022-11-09 16:22:24,614 BAD EPOCHS (no improvement): 1
2022-11-09 16:22:24,615 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:25,079 epoch 11 - iter 1/1 - loss 0.59573602 - samples/sec: 69.12 - lr: 0.025000
2022-11-09 16:22:25,080 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:25,080 EPOCH 11 done: loss 0.5957 - lr 0.025000
2022-11-09 16:22:29,992 Evaluating as a multi-label problem: False
2022-11-09 16:22:30,020 DEV : loss 0.6283536553382874 - f1-score (micro avg)  0.0
2022-11-09 16:22:30,139 BAD EPOCHS (no improvement): 2
2022-11-09 16:22:30,140 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:30,758 epoch 12 - iter 1/1 - loss 0.60090975 - samples/sec: 51.97 - lr: 0.025000
2022-11-09 16:22:30,759 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:30,760 EPOCH 12 done: loss 0.6009 - lr 0.025000
2022-11-09 16:22:36,620 Evaluating as a multi-label problem: False
2022-11-09 16:22:36,643 DEV : loss 0.6171218156814575 - f1-score (micro avg)  0.0
2022-11-09 16:22:36,753 BAD EPOCHS (no improvement): 3
2022-11-09 16:22:36,754 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:37,346 epoch 13 - iter 1/1 - loss 0.58521896 - samples/sec: 54.20 - lr: 0.025000
2022-11-09 16:22:37,347 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:37,348 EPOCH 13 done: loss 0.5852 - lr 0.025000
2022-11-09 16:22:43,217 Evaluating as a multi-label problem: False
2022-11-09 16:22:43,240 DEV : loss 0.6123790144920349 - f1-score (micro avg)  0.0
2022-11-09 16:22:43,350 Epoch    13: reducing learning rate of group 0 to 1.2500e-02.
2022-11-09 16:22:43,351 BAD EPOCHS (no improvement): 4
2022-11-09 16:22:43,352 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:43,945 epoch 14 - iter 1/1 - loss 0.54838764 - samples/sec: 54.05 - lr: 0.012500
2022-11-09 16:22:43,947 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:43,947 EPOCH 14 done: loss 0.5484 - lr 0.012500
2022-11-09 16:22:49,855 Evaluating as a multi-label problem: False
2022-11-09 16:22:49,881 DEV : loss 0.6088904738426208 - f1-score (micro avg)  0.0
2022-11-09 16:22:49,994 BAD EPOCHS (no improvement): 1
2022-11-09 16:22:49,996 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:50,598 epoch 15 - iter 1/1 - loss 0.55163549 - samples/sec: 53.26 - lr: 0.012500
2022-11-09 16:22:50,599 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:50,599 EPOCH 15 done: loss 0.5516 - lr 0.012500
2022-11-09 16:22:56,474 Evaluating as a multi-label problem: False
2022-11-09 16:22:56,498 DEV : loss 0.6031208038330078 - f1-score (micro avg)  0.0
2022-11-09 16:22:56,624 BAD EPOCHS (no improvement): 2
2022-11-09 16:22:58,337 ----------------------------------------------------------------------------------------------------
2022-11-09 16:22:58,339 loading file resources\taggers\example-ner\best-model.pt
2022-11-09 16:22:59,385 SequenceTagger predicts: Dictionary with 36 tags: <unk>, O, S-facility, B-facility, E-facility, I-facility, S-geo-loc, B-geo-loc, E-geo-loc, I-geo-loc, S-other, B-other, E-other, I-other, S-company, B-company, E-company, I-company, S-product, B-product, E-product, I-product, S-person, B-person, E-person, I-person, S-sportsteam, B-sportsteam, E-sportsteam, I-sportsteam, S-movie, B-movie, E-movie, I-movie, <START>, <STOP>
2022-11-09 16:23:22,785 Evaluating as a multi-label problem: False
2022-11-09 16:23:22,951 0.0008	0.0017	0.0011	0.0006
2022-11-09 16:23:22,953 
Results:
- F-score (micro) 0.0011
- F-score (macro) 0.0009
- Accuracy 0.0006

By class:
              precision    recall  f1-score   support

         nk>     0.0000    0.0000    0.0000         0
     geo-loc     0.0000    0.0000    0.0000       882
     company     0.0039    0.0064    0.0049       621
       movie     0.0012    0.0294    0.0023        34
       other     0.0075    0.0017    0.0028       584
    facility     0.0000    0.0000    0.0000       253
      person     0.0000    0.0000    0.0000       482
     product     0.0000    0.0000    0.0000       246
 musicartist     0.0000    0.0000    0.0000       191
  sportsteam     0.0000    0.0000    0.0000       147
      tvshow     0.0000    0.0000    0.0000        33

   micro avg     0.0008    0.0017    0.0011      3473
   macro avg     0.0011    0.0034    0.0009      3473
weighted avg     0.0020    0.0017    0.0014      3473

2022-11-09 16:23:22,959 ----------------------------------------------------------------------------------------------------
