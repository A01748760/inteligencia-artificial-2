2022-11-25 17:49:49,648 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,649 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)
  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=36, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-11-25 17:49:49,649 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,649 Corpus: "Corpus: 26 train + 1000 dev + 3850 test sentences"
2022-11-25 17:49:49,649 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,649 Parameters:
2022-11-25 17:49:49,649  - learning_rate: "0.050000"
2022-11-25 17:49:49,649  - mini_batch_size: "32"
2022-11-25 17:49:49,649  - patience: "3"
2022-11-25 17:49:49,650  - anneal_factor: "0.5"
2022-11-25 17:49:49,650  - max_epochs: "5"
2022-11-25 17:49:49,650  - shuffle: "True"
2022-11-25 17:49:49,650  - train_with_dev: "False"
2022-11-25 17:49:49,650  - batch_growth_annealing: "False"
2022-11-25 17:49:49,650 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,650 Model training base path: "resources\taggers\example-ner"
2022-11-25 17:49:49,650 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,650 Device: cpu
2022-11-25 17:49:49,650 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:49,650 Embeddings storage mode: cpu
2022-11-25 17:49:49,650 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:50,141 epoch 1 - iter 1/1 - loss 3.22456800 - samples/sec: 65.27 - lr: 0.050000
2022-11-25 17:49:50,141 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:50,142 EPOCH 1 done: loss 3.2246 - lr 0.050000
2022-11-25 17:49:54,596 Evaluating as a multi-label problem: False
2022-11-25 17:49:54,623 DEV : loss 2.841153621673584 - f1-score (micro avg)  0.0
2022-11-25 17:49:54,695 BAD EPOCHS (no improvement): 0
2022-11-25 17:49:54,696 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:55,163 epoch 2 - iter 1/1 - loss 2.82158691 - samples/sec: 68.71 - lr: 0.050000
2022-11-25 17:49:55,164 ----------------------------------------------------------------------------------------------------
2022-11-25 17:49:55,164 EPOCH 2 done: loss 2.8216 - lr 0.050000
2022-11-25 17:49:59,631 Evaluating as a multi-label problem: False
2022-11-25 17:49:59,662 DEV : loss 2.437859535217285 - f1-score (micro avg)  0.0
2022-11-25 17:49:59,735 BAD EPOCHS (no improvement): 0
2022-11-25 17:49:59,736 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:00,211 epoch 3 - iter 1/1 - loss 2.37221834 - samples/sec: 67.41 - lr: 0.050000
2022-11-25 17:50:00,212 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:00,212 EPOCH 3 done: loss 2.3722 - lr 0.050000
2022-11-25 17:50:04,611 Evaluating as a multi-label problem: False
2022-11-25 17:50:04,640 DEV : loss 2.0153985023498535 - f1-score (micro avg)  0.0
2022-11-25 17:50:04,720 BAD EPOCHS (no improvement): 0
2022-11-25 17:50:04,721 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:05,159 epoch 4 - iter 1/1 - loss 1.90103387 - samples/sec: 73.10 - lr: 0.050000
2022-11-25 17:50:05,160 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:05,160 EPOCH 4 done: loss 1.9010 - lr 0.050000
2022-11-25 17:50:09,444 Evaluating as a multi-label problem: False
2022-11-25 17:50:09,482 DEV : loss 1.5655760765075684 - f1-score (micro avg)  0.0054
2022-11-25 17:50:09,565 BAD EPOCHS (no improvement): 0
2022-11-25 17:50:09,565 saving best model
2022-11-25 17:50:10,640 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:11,117 epoch 5 - iter 1/1 - loss 1.57054328 - samples/sec: 67.40 - lr: 0.050000
2022-11-25 17:50:11,117 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:11,117 EPOCH 5 done: loss 1.5705 - lr 0.050000
2022-11-25 17:50:15,815 Evaluating as a multi-label problem: False
2022-11-25 17:50:15,842 DEV : loss 1.1474709510803223 - f1-score (micro avg)  0.0027
2022-11-25 17:50:15,921 BAD EPOCHS (no improvement): 1
2022-11-25 17:50:17,031 ----------------------------------------------------------------------------------------------------
2022-11-25 17:50:17,033 loading file resources\taggers\example-ner\best-model.pt
2022-11-25 17:50:17,652 SequenceTagger predicts: Dictionary with 36 tags: <unk>, O, S-facility, B-facility, E-facility, I-facility, S-geo-loc, B-geo-loc, E-geo-loc, I-geo-loc, S-other, B-other, E-other, I-other, S-company, B-company, E-company, I-company, S-product, B-product, E-product, I-product, S-person, B-person, E-person, I-person, S-sportsteam, B-sportsteam, E-sportsteam, I-sportsteam, S-movie, B-movie, E-movie, I-movie, <START>, <STOP>
2022-11-25 17:50:35,728 Evaluating as a multi-label problem: False
2022-11-25 17:50:35,853 0.0027	0.0095	0.0041	0.0021
2022-11-25 17:50:35,853 
Results:
- F-score (micro) 0.0041
- F-score (macro) 0.0021
- Accuracy 0.0021

By class:
              precision    recall  f1-score   support

     geo-loc     0.0063    0.0249    0.0101       882
      person     0.0015    0.0104    0.0027       482
         nk>     0.0000    0.0000    0.0000         0
     product     0.0025    0.0163    0.0044       246
     company     0.0000    0.0000    0.0000       621
  sportsteam     0.0038    0.0136    0.0060       147
       other     0.0000    0.0000    0.0000       584
    facility     0.0000    0.0000    0.0000       253
 musicartist     0.0000    0.0000    0.0000       191
       movie     0.0000    0.0000    0.0000        34
      tvshow     0.0000    0.0000    0.0000        33

   micro avg     0.0027    0.0095    0.0041      3473
   macro avg     0.0013    0.0059    0.0021      3473
weighted avg     0.0022    0.0095    0.0035      3473

2022-11-25 17:50:35,853 ----------------------------------------------------------------------------------------------------
